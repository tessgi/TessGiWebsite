{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction into the Lightkurve Corrector Class - Noise removal for TESS light curves\n",
    "Welcome everyone to our *TESS* Lightkurve tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "[Rebekah Hounsell](https://heasarc.gsfc.nasa.gov/docs/tess/helpdesk.html) - Support scientist for *TESS* in the NASA GSFC GI Office. \n",
    "\n",
    "<img src=\"helpdesk.png\" style=\"width: 80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2yAwPl-XENV"
   },
   "source": [
    "## Learning Goals\n",
    "\n",
    "In this tutorial, we will teach the user how to remove scattered light and noise from a *TESS* light curve. \n",
    "\n",
    "The splinter session assumes a basic knowledge of python and astronomy, and will walk the user through several of the concepts outlined below,\n",
    "\n",
    "1. How to use *Lightkurve* to access the various data products and create time series.\n",
    "2. How to account for instrumental and noise effects within your data using the Corrector class.\n",
    "\n",
    "This tutorial is designed for users that have previous experience with *Lightkurve*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnTUKQjlYHeh"
   },
   "source": [
    "## Imports\n",
    "\n",
    "This tutorial requires the use of specific packages:\n",
    "- [**Lightkurve**](https://docs.lightkurve.org/index.html) to work with *TESS* data (v2.0.1)\n",
    "- [**Matplotlib**](https://matplotlib.org/) for plotting.\n",
    "- [**Numpy**](https://numpy.org) for manipulating the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrmknoO9jt5F",
    "outputId": "048c1e1b-f1b3-4d37-fd4d-3214d1bda24b"
   },
   "source": [
    "## First time users\n",
    "\n",
    "If you are not that experienced with *Python*, or cannot download *Lightkurve*, you can run this notebook as a [Colab notebook](https://colab.research.google.com/notebooks/intro.ipynb?utm_source=scs-index). Colaboratory allows users to write and execute *Python* in your browser with zero configuration required. \n",
    "\n",
    "All you need is a Google account and to copy and paste in the following command at the top of your colab notebook:\n",
    "\n",
    "`!pip install lightkurve`\n",
    "\n",
    "This downloads the *Lightkurve* package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dS_W-DWjoEu0"
   },
   "outputs": [],
   "source": [
    "import lightkurve as lk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLzQXfvBYUTL"
   },
   "source": [
    "## Introduction to the Corrector Class\n",
    "\n",
    "*TESS* light curves can often have systematic trends caused by noise sources such as scattered light and instrumental effects. Only the [LightCurve objects](https://docs.lightkurve.org/tutorials/1-getting-started/what-are-lightcurve-objects.html) which have been fully processed, have had these effects removed. Data derived from either [TargetPixelFiles](https://docs.lightkurve.org/tutorials/1-getting-started/what-are-targetpixelfile-objects.html) or Full Frame Images must undergo further processing by the user to remove these sources of noise. \n",
    "\n",
    "To aid the user in this process, there exist several different tools within the \n",
    "*Lightkurve* package. These are known as the [Corrector class](https://docs.lightkurve.org/reference/api/lightkurve.correctors.corrector.Corrector.html?highlight=corrector%20class#lightkurve-correctors-corrector-corrector). We briefly describe each of these corrector classes below,\n",
    "\n",
    "- [**CBVCorrector**](https://docs.lightkurve.org/reference/api/lightkurve.correctors.CBVCorrector.html?highlight=cbvcorrector): Cotrending Basis Vectors (CBVs) are generated from the most common systematic trends observed in each Sector. Each *TESS* CCD and Camera has its own set of CBVs. There are three basic types of CBVs, \n",
    "  - **Single-Scale**: Contains all systematic trends combined in a single set of basis vectors. Generally speaking, a single-scale CBV performs better at preserving longer period signals.\n",
    "  - **Multi-Scale**: Contains systematic trends in specific wavelet-based band passes. There are usually three sets of multi-scale basis vectors in three bands. This type of correction performs better when the periods are close to the transiting planet durations, and help to preserve the signal.\n",
    "  - **Spike**: Contains only short impulsive spike systematics. This correction is applied to remove short impulsive systematic signals.\n",
    "  \n",
    "\n",
    "- [**RegressionCorrector**](https://docs.lightkurve.org/reference/api/lightkurve.correctors.RegressionCorrector.html?highlight=regressioncorrector): Here the light curve is de-trended against vectors that we think are predictive of the systematic noise. For FFI data, we have to select/define an aperture for our object of interest. Pixels outside of this aperture are used to create vectors that are predictive of the noise. These vectors are then removed from the data.\n",
    "\n",
    "- [**PLDCorrector**](https://docs.lightkurve.org/reference/api/lightkurve.correctors.PLDCorrector.html?highlight=pldcorrector): Pixel Level De-correlation (PLD) works by identifying a set of trends in the pixels surrounding the target star, and performing linear regression to create a combination of these trends that effectively models the systematic noise introduced by spacecraft motion/scattered light. This noise model is then subtracted from the uncorrected light curve. It is similar to the RegressionCorrector.\n",
    "\n",
    "In this tutorial, we will apply each of these methods to our data and compare the results. First, we need to obtain the data to test our various Corrector functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NAo0xYmnf8f"
   },
   "source": [
    "## 1. How to use *Lightkurve* to access the various data products and create a time series\n",
    "\n",
    "\n",
    "[*Lightkurve*](https://docs.lightkurve.org/tutorials/index.html) offers a user-friendly way to analyze time series data obtained by telescopes, in particular *TESS*. You can search for the various data products for *TESS* on MAST using the following *Lightkurve* functions.\n",
    "\n",
    "- To look for your object in a full frame image: [`search_tesscut()`](https://docs.lightkurve.org/reference/api/lightkurve.search_tesscut.html?highlight=search_tesscut)\n",
    "\n",
    "- To look for target pixel files:  [`search_targetpixelfile()`](https://docs.lightkurve.org/reference/api/lightkurve.search_targetpixelfile.html?highlight=search_targetpixelfile) \n",
    "\n",
    "- To obtain light curve files for your object of interest: [`search_lightcurve()`](https://docs.lightkurve.org/reference/api/lightkurve.search_lightcurve.html?highlight=search_lightcurve) \n",
    "\n",
    "For the purpose of this tutorial, we will be examining [KT Eri](https://en.wikipedia.org/wiki/KT_Eridani), a bright nova in the constellation Eridanus that underwent an eruption in 2009.\n",
    "\n",
    "To test our various methods of noise removal, we will be looking at FFI data for this object. We can search [MAST](https://mast.stsci.edu) for TESS FFI data on this object using the [search_tesscut()](https://docs.lightkurve.org/reference/api/lightkurve.search_tesscut.html?highlight=search_tesscut#lightkurve.search_tesscut) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "a_KEML4eojAA",
    "outputId": "eed270a7-8e68-43ca-cd48-e59148ad58ef"
   },
   "outputs": [],
   "source": [
    "search_lc = lk.search_tesscut(\"KT Eri\")\n",
    "search_lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqvplNZ7n83T"
   },
   "source": [
    "We see that there are two sets of data, one from Sector 5 and the other from Sector 32. Let's look at the data from Sector 32. To download the data we must specify a cut out size in pixels and use the [download()](https://docs.lightkurve.org/reference/search.html?highlight=download) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "us4RpuK7pVvB",
    "outputId": "fc16bf0e-e6fd-420a-964d-c0eb1cdccecd"
   },
   "outputs": [],
   "source": [
    "S32 = search_lc[1].download(cutout_size=50)\n",
    "S32.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this cut out is much larger than a typical FFI, this is because when calculating our noise and systematics, we want a larger sample of pixels from which the correction will be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SrO8uNNojYV"
   },
   "source": [
    "**Creating our light curve**\n",
    "\n",
    "Great! Now we have our data, we can create our light curve using the  [to_lightcurve()](https://docs.lightkurve.org/reference/api/lightkurve.KeplerTargetPixelFile.to_lightcurve.html?highlight=to_lightcurve#lightkurve.KeplerTargetPixelFile.to_lightcurve) function. Our object is in the center, but it is kind of faint in comparison to some other objects. We must therefore create our own aperture as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "vNsFsxcXpyPy",
    "outputId": "2686d9ea-185c-46a9-8943-088e6c20ae49"
   },
   "outputs": [],
   "source": [
    "aper_new = np.zeros(S32.shape[1:], dtype=bool)\n",
    "aper_new[24:27, 24:27] = True\n",
    "S32.plot(aperture_mask=aper_new, mask_color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qlB175rsKjr"
   },
   "source": [
    "Excellent it covers our object! Let's now make our light curve using this aperture and plot the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "60ceFL3Xw-X0",
    "outputId": "732b6a56-9704-4b91-9c29-9209044718dd"
   },
   "outputs": [],
   "source": [
    "lc_S32 = S32.to_lightcurve(aperture_mask=aper_new)\n",
    "lc_S32.plot(label=\"S32 FFI lc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S32.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOAT8xRfu2um"
   },
   "source": [
    "## 2. How to account for instrumental and noise effects within your data using the Corrector class\n",
    "\n",
    "We can see from the above plot that our light curve is severely affected by scattered light, which needs to be removed. To remove this noise, let's try our first method,\n",
    "\n",
    "### The CBVCorrector\n",
    "\n",
    "Here we will use CBVs to remove our noise. \n",
    "\n",
    "Check out our [CBV tutorial](https://docs.lightkurve.org/tutorials/2-creating-light-curves/2-3-how-to-use-cbvcorrector.html) for more information.\n",
    "\n",
    "First, we must import the *CBVCorrector* from *lightkurve.correctors*, and then we can refer to our generate light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Am50Zngwu2YE",
    "outputId": "3b4c7ae3-3d6c-4654-87a0-a13da01606e5"
   },
   "outputs": [],
   "source": [
    "from lightkurve.correctors import CBVCorrector\n",
    "cbvCorrector = CBVCorrector(lc_S32, interpolate_cbvs=True)\n",
    "cbvCorrector.cbvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUCqDhB1wzwL"
   },
   "source": [
    "There are 5 sets of CBVs, all associated with Sector 32, Camera 2, CCD 4. The number of CBVs per type is also given. Let’s plot the Single-Scale CBVs, which contain all systematics combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "9fsOncnWwwly",
    "outputId": "2ed09fd7-50f9-4929-f09a-05bbb62a1c53"
   },
   "outputs": [],
   "source": [
    "cbvCorrector.cbvs[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvTDdDUKxKVL"
   },
   "source": [
    "The first several CBVs contain most of the systematics. The latter CBVs pose a greater risk of injecting more noise than helping. The default behavior in CBVCorrector is to use the first 8 CBVs.\n",
    "\n",
    "Next, we need to decide what kind of CBV we want to apply. Since we want to try not to overfit, we are going to use the Multi-Scale and Spike options (see above for more details). We can specify the type via an array as indicated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0q8V__dO2Qjz"
   },
   "outputs": [],
   "source": [
    "cbv_type = ['MultiScale.1', 'MultiScale.2', 'MultiScale.3','Spike']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh-vw_Og_Qys"
   },
   "source": [
    "Since we only want to use the information from the first 8 CBV's when we use the SingleScale function, and all the Spike CBCs, we must also specify this via an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeUzqrFF_MQP"
   },
   "outputs": [],
   "source": [
    "cbv_indices = [np.arange(1,9), np.arange(1,9), np.arange(1,9), 'ALL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrQiT-e89s3u"
   },
   "source": [
    "Now we want to check that the application of these vectors will not under or over-fit our data. There is a handy way of checking this via the use of a goodness_metric_scan_plot. A \"Goodness Metric\" value of 0.8 and above tends to indicate a good fit to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "vpQPnqMq_hOC",
    "outputId": "8b35c8c4-4e53-4498-f9b0-bb284f875d24"
   },
   "outputs": [],
   "source": [
    "cbvCorrector.goodness_metric_scan_plot(cbv_type=cbv_type, cbv_indices=cbv_indices);\n",
    "plt.plot([1.5e-1, 1.5e-1], [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QV_DpOkBAEPT"
   },
   "source": [
    "The above plot indicates that a regularization factor alpha value of 1.5e-1 is appropriate for our data. We can now specify this and check it via a diagnose method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "Sqc5ALeAAZ3D",
    "outputId": "27a3f995-4444-42b2-a6a1-e2cef2a010de"
   },
   "outputs": [],
   "source": [
    "cbvcorrector = CBVCorrector(lc_S32, interpolate_cbvs=True)\n",
    "cbvcorrector.correct_gaussian_prior(cbv_type=cbv_type, cbv_indices=cbv_indices, alpha=1.5e-1)\n",
    "pltAxis = cbvcorrector.diagnose()\n",
    "#pltAxis[0].set_ylim(0, 500);\n",
    "#pltAxis[1].set_ylim(0, 500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "9NCJUTQOpIqJ",
    "outputId": "869fbf6b-060a-426e-97ad-d0cb61230df3"
   },
   "outputs": [],
   "source": [
    "cbvcorrector_lc = cbvcorrector.corrected_lc\n",
    "cbvcorrector_lc.remove_outliers().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UW4vrQ3xJUNG"
   },
   "source": [
    "We can see that a correction was applied which has removed some of the slope from our data and also labeled the big spike as an outlier. \n",
    "\n",
    "The above method can be adjusted more, but for now, let's move onto our next method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJDB51reJdkH"
   },
   "source": [
    "### The RegressionCorrector\n",
    "\n",
    "Remember that this method relies on looking at pixels outside of our previously defined object aperture to determine our systematics. We can apply regression correction as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdeNuOLuPrWM"
   },
   "outputs": [],
   "source": [
    "#Import the packages you need\n",
    "from lightkurve.correctors import RegressionCorrector, DesignMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vExpAJpBXW0x"
   },
   "source": [
    "Next, we are going to define a design matrix which will contain all the systematics detected in the pixels outside of our aperture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ezey-LBXyCV"
   },
   "outputs": [],
   "source": [
    "# Make a design matrix and pass it to a linear regression corrector\n",
    "dm = DesignMatrix(S32.flux[:, ~aper_new], name='regressors')#.pca(5).append_constant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We only want the most dominant vectors and so specify the number of principle componant (PCA) as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = dm.pca(10)\n",
    "plt.plot(S32.time.value, dm.values + np.arange(10)*0.2, '.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that 10 is excessive and we should probably use only 5. Let's do this and plot it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DesignMatrix(S32.flux[:, ~aper_new], name='regressors').pca(5)\n",
    "dm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzM3E8WCX56e"
   },
   "source": [
    "\n",
    "*Lightkurve’s RegressionCorrector* uses linear algebra to find the combination of vectors that makes the input light curve closest to zero. We therefore needed to add one more component - an “offset” term, to be able to fit the mean level of the light curve. We can do this as shown above by appending a“constant” to the design matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DesignMatrix(S32.flux[:, ~aper_new], name='regressors').pca(5).append_constant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we pass this design matrix to the *RegressionCorrector* which de-trends the light curves against the vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "K080X2P4X1Um",
    "outputId": "dd5888c3-b6c5-4b4e-82d3-4edab8801e36"
   },
   "outputs": [],
   "source": [
    "rc = RegressionCorrector(lc_S32)\n",
    "rc.correct(dm)\n",
    "pltAxis = rc.diagnose()\n",
    "pltAxis[0].set_ylim(0, 2000);\n",
    "pltAxis[1].set_ylim(0, 2000);\n",
    "\n",
    "corrected_ffi_lc = rc.correct(dm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEQIDQbMckDN"
   },
   "source": [
    "**HOWEVER!** The *RegressionCorrector* assumes that you want to remove the trend and set the light curve to the mean level. \n",
    "\n",
    "This isn’t true for *TESS* scattered light, as the *TESS* FFI light curves have an additive background. As such, we want to reduce the flux to the lowest recorded level.\n",
    "\n",
    "To do this, we can look at the model of the background that *RegressionCorrector* built and apply that.  This model should never go below zero, to ensure that this is the case we only subtract the model flux value at the 5th percentile.\n",
    "\n",
    "We can then apply all these factors to the FFI light curve using the following code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "gybYr3l9aJ9l",
    "outputId": "321fe699-b086-42c1-d018-c6550eb427e4"
   },
   "outputs": [],
   "source": [
    "# Optional: Remove the scattered light, allowing for the large offset from scattered light\n",
    "corrected_ffi_lc = lc_S32 - rc.model_lc + np.percentile(rc.model_lc.flux, 5)\n",
    "corrected_ffi_lc.plot(label='Corrected light curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0ghY9DaeKIc"
   },
   "source": [
    "This has removed all the scattered light and the slope, but again could be adjusted further. However, we will move onto our final tool.\n",
    "\n",
    "### The PLDCorrector\n",
    "\n",
    "PLD is built on top of *RegressionCorrector* and again works by identifying a set of trends in the pixels surrounding the target star, and performing linear regression to create a combination of these trends that effectively models the noise. This noise model is then subtracted from the uncorrected light curve. The difference between *PLDCorrector* and *RegressionCorrector* is that *RegressionCorrector* asks the user to define the pixels, where as *PLDCorrector* does not.\n",
    "\n",
    "We will create a *PLDCorrector* object, and use the default values for PLDCorrector.correct to remove this scattered light background.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "pCIleUJR186M",
    "outputId": "05109b51-6eb2-449f-e4c7-1f91c010330c"
   },
   "outputs": [],
   "source": [
    "from lightkurve.correctors import PLDCorrector\n",
    "pld_S32 = PLDCorrector(S32)\n",
    "pld_S32.correct(pca_components=5)\n",
    "pltAxis = pld_S32.diagnose()\n",
    "pltAxis[0].set_ylim(0, 500);\n",
    "pltAxis[1].set_ylim(0, 500);\n",
    "pltAxis[2].set_ylim(0, 500);\n",
    "\n",
    "corrected_pldlc = pld_S32.correct(pca_components=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also examine the apertures used to perform this correction. For *TESS*, the dominant source of noise is the scattered light background, so by default only those pixels will be used. In the third panel, we can see that the background_aperture_mask contains only background pixels, reducing the risk of contamination by neighboring stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pld_S32.diagnose_masks();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets specifically look at our corrected light curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_pldlc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxQlYbhymWDp"
   },
   "source": [
    "The large spike from the scattered light has sucessfully been identified and removed, but there is a slope in our data still. We can determine from the diagnostic plots that this is due to the application of a flat background, unlike that which was applied in *RegressionCorrection*.\n",
    "\n",
    "Note that there are various componants that can be altered in *PLD* most of which can be found [here](https://docs.lightkurve.org/reference/api/lightkurve.correctors.PLDCorrector.correct.html?highlight=pca_components). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNCM407j3YL-"
   },
   "source": [
    "## Comparison\n",
    "\n",
    "Let's now plot up all of our corrected light curves in addition to the light curve originally derived from the FFI's, and compare our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "zY3xJhZy3z-J",
    "outputId": "ec5942a9-6a28-4c65-8c65-24af16ac7b72"
   },
   "outputs": [],
   "source": [
    "# Lets plot and compare the different methods \n",
    "ax = lc_S32.normalize().remove_outliers().scatter(color='black', label='Uncorrected Light Curve');\n",
    "# Plot the CBV-corrected light curve in green\n",
    "cbvcorrector_lc.normalize().remove_outliers().scatter(ax=ax, color='green', label='CBV-corrected Light Curve')\n",
    "# Plot the regressor-corrected light curve in blue\n",
    "corrected_ffi_lc.normalize().remove_outliers().scatter(ax=ax, color='blue', label='Regressor-corrected Light Curve')\n",
    "# Plot the PLD-corrected light curve in red \n",
    "corrected_pldlc.normalize().remove_outliers().scatter(ax=ax, color='red', label='PLD-corrected Light Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bsh4mwTL5MLf"
   },
   "source": [
    "## Summary\n",
    "\n",
    "The plot above indicaates that there is no one solution. The result from the *RegressionCorrector* seems to have removed the most scattered light and the slope in the data, whilst retaining the periodicity. \n",
    "\n",
    "As you may have discovered, removing the noise from the data can be a complex issue with multiple paths. You should always examine your method of noise removal and inspect all final products. \n",
    "\n",
    "The tutorials listed below will aid you in better understanding the fine details of each process.\n",
    "\n",
    "- [Removing noise from Kepler, K2, and TESS light curves using Cotrending Basis Vectors (CBVCorrector)](https://docs.lightkurve.org/tutorials/2-creating-light-curves/2-3-how-to-use-cbvcorrector.html)\n",
    "- [Removing scattered light from TESS light curves using linear regression (RegressionCorrector)](https://docs.lightkurve.org/tutorials/2-creating-light-curves/2-3-removing-scattered-light-using-regressioncorrector.html)\n",
    "- [Removing noise from K2 and TESS light curves using Pixel Level Decorrelation (PLDCorrector)](https://docs.lightkurve.org/tutorials/2-creating-light-curves/2-3-k2-pldcorrector.html)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NoiseRemoval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
