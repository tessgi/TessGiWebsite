{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Crowding in TESS data\n",
    "\n",
    "Welcome everyone to this *TESS* Lightkurve tutorial!\n",
    "\n",
    "## Authors\n",
    "\n",
    "[Rebekah Hounsell](https://heasarc.gsfc.nasa.gov/docs/tess/helpdesk.html) - Support scientist for *TESS* in the NASA GSFC GI Office. \n",
    "\n",
    "<img src=\"helpdesk.png\" style=\"width: 80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "In this tutorial, we will teach the user about crowding in the *TESS* data products and how to correct for it. \n",
    "\n",
    "The splinter session assumes a basic knowledge of python and astronomy, and will walk the user through several of the concepts outlined below:\n",
    "\n",
    "1. Downloading and comparing LightCurve Object data\n",
    "2. Examining a TargetPixel File (TPF) for crowding\n",
    "3. Creating a light curve from a TPF\n",
    "4. Removing the effects of scattered light and noise\n",
    "5. Removing the effects of crowding\n",
    "\n",
    "This tutorial is designed for users that have previous experience with *Lightkurve*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "This tutorial requires the use of specific packages:\n",
    "- [**Lightkurve**](https://docs.lightkurve.org/index.html) to work with *TESS* data (v2.0.1)\n",
    "- [**Matplotlib**](https://matplotlib.org/) for plotting.\n",
    "- [**Numpy**](https://numpy.org) for manipulating the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First time users\n",
    "\n",
    "If you are not that experienced with *Python*, or cannot download *Lightkurve*, you can run this notebook as a [Colab notebook](https://colab.research.google.com/notebooks/intro.ipynb?utm_source=scs-index). Colaboratory allows users to write and execute *Python* in your browser with zero configuration required. \n",
    "\n",
    "All you need is a Google account and to copy and paste in the following command at the top of your colab notebook:\n",
    "\n",
    "`!pip install git+https://github.com/lightkurve/lightkurve.git --quiet`\n",
    "\n",
    "This downloads the *Lightkurve* package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "from lightkurve.correctors import RegressionCorrector, DesignMatrix\n",
    "from lightkurve.correctors import PLDCorrector\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction into crowding \n",
    "\n",
    "*TESS* photometry, while high-cadence and of high quality, does suffer from crowding issues. \n",
    "A single *TESS* pixel corresponds to 21 arcseconds (~0.35 arc min) on sky and the *TESS* Pixel Response Function (PRF) is very large compared to the pixel. A target of interest may therefore be contaminated by any number of neighboring objects, and it is important that the light from these other objects be accounted for and removed. \n",
    "\n",
    "For exoplanets, if this excess flux is not removed, it can cause a decrease in the apparent planet transit depth and lead to a systematic underestimation of the planet radii.\n",
    "\n",
    "[LightCurve Objects](https://docs.lightkurve.org/tutorials/1-getting-started/what-are-lightcurve-objects.html) have been corrected for this crowding via the data processing pipeline developed by the Science Processing Operations Center (SPOC). A description of this correction and its application is provided in Section 2.3.11 of [this paper](https://iopscience.iop.org/article/10.1086/667698/pdf). The correction however is applied only to the PDCSAP flux and not the SAP flux. \n",
    "\n",
    "The crowding correction applied focuses on two parameters:\n",
    " - The crowding metric: This reflects what fraction of the flux in the aperture is due to the target itself, not the nearby light sources. \n",
    " - The flux fraction: Similar to excess flux leaking into the aperture, a fraction of the PRF of the target may not be captured in it. To account for this missing fraction, the flux fraction is computed.\n",
    " \n",
    "If PDCSAP flux is not available, the user may apply the corrections outlined below to remove not only the instrumental noise, but any additional crowding effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading and comparing LightCurve Object data\n",
    "\n",
    "In this tutorial we will be examining at the binary star system [WR21a](https://en.wikipedia.org/wiki/WR_21a). Let's first see if there are any LightCurve objects avalible for download. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_lk = lk.search_lightcurve(\"WR21a\")\n",
    "search_lk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, great! There are data for multiple sectors. For this tutorial, we will examining data from Sector 36 which is provided by the SPOC. We can download this via the following functions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc36 = search_lk[2].download()\n",
    "lc36.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This very clearly shows the transit of the system. The flux displayed is the PDCSAP flux which has been fully corrected. Let's see what the SAP flux looks like in comparison. We can do this by specifying the column in the plot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = lc36.scatter(normalize=False, label='PDCSAP')\n",
    "lc36.scatter(ax=ax, column='sap_flux', normalize=False, color='red', label='SAP')\n",
    "plt.xlim(xmin=2290, xmax=2293)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The above plot clearly indicates the significant difference in amplitude between the PDCSAP and SAP flux. The plot illustrates how much of a difference the flux fraction and crowding metric can change the absolute magnitudes of the light curves.\n",
    "\n",
    "Now we plot the normalized PDCSAP and SAP flux to show that the transit depth has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc36.scatter(normalize=True, label='PDCSAP')\n",
    "lc36.scatter(ax=ax, column='sap_flux', normalize=True, color='red', label='SAP')\n",
    "plt.xlim(xmin=2290, xmax=2293)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transit depth of the SAP flux is not the same as the PDCSAP. This difference is a good indication that the data suffers from crowding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examining a Target Pixel File for crowding\n",
    "\n",
    "To fully appreciate how crowded our object is, we can examine its surroundings via downloading and plotting the associated TargetPixel File (TPF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpf = lk.search_targetpixelfile('WR21a', sector=36).download(quality_bitmask='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for this tutorial we are specifing the `quality_bitmask` to be 'hard'. This is to ensure that only good quality data is downloaded. We can now plot our TPF and display the aperture mask that has been defined by the SPOC for our object of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpf.plot(aperture_mask=tpf.pipeline_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot indicates that we are focusing on the right object, but that it is indeed crowded by a much brighter star and as such, we need to remove the contaminating flux.\n",
    "\n",
    "\n",
    "## 3. Creating a light curve from a TPF \n",
    "To do this, we must first create the light curve of the object using the default mask, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpf_lc = tpf.to_lightcurve(aperture_mask=tpf.pipeline_mask)\n",
    "tpf_lc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick glance at this light curve indicates that there are also long term trends/noise that need to be removed before we can correct for crowding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Removing the effects of scattered light and noise\n",
    "\n",
    "As indicated above, the SAP light curve is effected by scattered light and noise. We must remove this before correcting for crowding. To do this, we can used one of *Lighkurves* built in corrector functions, in this case [Pixel Level Decorrelation (PLD)](https://docs.lightkurve.org/tutorials/2-creating-light-curves/2-3-k2-pldcorrector.html).\n",
    "\n",
    "The inputs required are the TPF, the aperture, and the number of principal componants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pld = PLDCorrector(tpf, aperture_mask=tpf.pipeline_mask)\n",
    "pld.correct(pca_components=5)\n",
    "pltAxis = pld.diagnose()\n",
    "pltAxis[0].set_ylim(ymin=6000, ymax=8000)\n",
    "pltAxis[1].set_ylim(ymin=6000, ymax=8000)\n",
    "pltAxis[2].set_ylim(ymin=6000, ymax=8000)\n",
    "\n",
    "\n",
    "pld.diagnose_masks();\n",
    "pld_lc = pld.correct(pca_components=5, aperture_mask=tpf.pipeline_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this corrected light curve with our previous light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc36.scatter(normalize=True, label='PDCSAP')\n",
    "tpf_lc.scatter(ax=ax, normalize=True, color='red', label='SAP ORIGINAL')\n",
    "pld_lc.scatter(ax=ax, normalize=True, color='green', label='PLD SAP')\n",
    "plt.xlim(xmin=2290, xmax=2293)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The depth of the PLD SAP light curve still does not match that of the PDCSAP, but there is some improvement in the light curve overall. Let's now apply the crowding correction to the pld_lc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Removing the effects of crowding\n",
    "\n",
    "To do this, we must first pull out the two parameters we need to calculate the correction - CROWDSAP and FLFRCSAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROWDSAP = tpf.hdu[1].header['CROWDSAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROWDSAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLFRCSAP = tpf.hdu[1].header['FLFRCSAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLFRCSAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above values, we see that the aperture contains only 71% of the object's flux, and an extra 21% of the flux in the aperture is due to other objects.\n",
    "\n",
    "To correct for the crowding and missing flux, we must first calculate the median flux of our time series. Note that we want only data that is of a high quality, which is why we originally set our `quality_mask` as hard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_flux = np.median(pld_lc.flux.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The excess flux in the aperture is then calculated as (1-CROWDSAP) times the median flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excess_flux = (1-CROWDSAP)*median_flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This excess flux must then be subtracted from the time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_removed = pld_lc.flux.value  - excess_flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This residual flux, however, does not account for the flux of our object outside of the aperture, as such there is one more correction to apply - FLFRCSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_corr = flux_removed/FLFRCSAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncertainties on this flux are also now altered to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_err_corr = pld_lc.flux_err.value/FLFRCSAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now convert this into a LightCurve Object again via the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_corr = lk.LightCurve(time=tpf.time.value, flux=flux_corr, flux_err=flux_err_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot and compare to our previous light curves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc36.scatter(normalize=True, label='PDCSAP')\n",
    "tpf_lc.scatter(ax=ax, normalize=True, color='red', label='SAP ORIGINAL', alpha=0.5)\n",
    "pld_lc.scatter(ax=ax, normalize=True, color='green', label='PLD SAP', alpha=0.5)\n",
    "lc_corr.scatter(ax=ax, normalize=True, color='blue', label='PLD SAP CORR', alpha=0.5)\n",
    "plt.xlim(xmin=2290, xmax=2293)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(lc_corr.flux.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corrected light curve is now significantly closer to that of the PLDSAP light curve. There are still some minor descrpancies,  but these are are realated primarily to the removal of noise. Adjustments in the noise removal procedure applied to the SAP light curve can further improve this reduction.\n",
    "\n",
    "Let's try another method - the CBV corrector.\n",
    "\n",
    "## CBVCorrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightkurve.correctors import CBVCorrector\n",
    "cbvCorrector = CBVCorrector(tpf_lc)\n",
    "cbvCorrector.cbvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which CBVs to use in the correction\n",
    "cbv_type = ['SingleScale', 'Spike']\n",
    "cbv_indices = [np.arange(1,9), 'ALL']\n",
    "# Perform the correction\n",
    "cbvCorrector.correct_gaussian_prior(cbv_type=cbv_type, cbv_indices=cbv_indices, alpha=1e-4)\n",
    "cbvCorrector.diagnose();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see if we have over or underfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    # ignore \"RuntimeWarning\"\n",
    "    warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "    cbvCorrector.goodness_metric_scan_plot(cbv_type=cbv_type, cbv_indices=cbv_indices);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might be slightly overfitting, so let's adjust our alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbvCorrector.correct_gaussian_prior(cbv_type=cbv_type, cbv_indices=cbv_indices, alpha=1e-1)\n",
    "cbvCorrector.diagnose();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the crowding corrections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the FF and CM corrections\n",
    "median_flux = np.median(cbvCorrector.corrected_lc.flux.value)\n",
    "excess_flux = (1-CROWDSAP)*median_flux\n",
    "flux_removed = cbvCorrector.corrected_lc.flux.value  - excess_flux\n",
    "flux_corr = flux_removed/FLFRCSAP\n",
    "flux_err_corr = cbvCorrector.corrected_lc.flux_err.value/FLFRCSAP\n",
    "lc_cbv_corr = lk.LightCurve(time=tpf.time.value, flux=flux_corr, flux_err=flux_err_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare to the PDCSAP and SAP light curves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = tpf_lc.scatter(normalize=True, color='red', label='SAP ORIGINAL')\n",
    "lc36.scatter(ax=ax, normalize=True, label='PDCSAP')\n",
    "lc_cbv_corr.scatter(ax=ax, normalize=True, color='cyan', label='CBV Corrected', alpha=0.5)\n",
    "plt.xlim(xmin=2290, xmax=2293);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compare our PLD and CBV corrected light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lc36.scatter(normalize=True, label='PDCSAP')\n",
    "lc_cbv_corr.scatter(ax=ax, normalize=True, color='cyan', label='CBV Corrected')\n",
    "lc_corr.scatter(ax=ax, normalize=True, color='blue', label='PLD SAP CORR', alpha = 0.5)\n",
    "plt.title('Comparing PLD correction to CBV Correction')\n",
    "plt.xlim(xmin=2290, xmax=2293);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CBV light curve might be a better match to the PDCSAP. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
